{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "VLAVenv2",
      "display_name": "VLAVenv2",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# ABSOLUTE PATH to your experiments directory (edit if needed!)\n",
        "sys.path.insert(0, \"/user_data/sraychau/Storage/ActualProject/openvla-main/experiments\")\n",
        "sys.path.insert(0, \"/user_data/sraychau/Storage/ActualProject/Lec14a_camera_sensor\")\n",
        "\n",
        "import numpy as np\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from typing import Union, Optional\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "# --- Project-specific imports ---\n",
        "from Lec14a_camera_sensor.mujoco_gym_env import MujocoSimpleEnv\n",
        "from robot.robot_utils import (\n",
        "    get_model,\n",
        "    get_action,\n",
        "    get_image_resize_size,\n",
        "    set_seed_everywhere,\n",
        "    invert_gripper_action,\n",
        ")\n",
        "from robot.openvla_utils import get_processor\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@dataclass\n",
        "class GenerateConfig:\n",
        "    # Model parameters\n",
        "    model_family: str = \"openvla\"\n",
        "    pretrained_checkpoint: Union[str, Path] = \"\"\n",
        "    load_in_8bit: bool = False\n",
        "    load_in_4bit: bool = False\n",
        "    center_crop: bool = False\n",
        "    unnorm_key: Optional[str] = None\n",
        "    # Env parameters\n",
        "    num_episodes: int = 5\n",
        "    max_steps: int = 100\n",
        "    image_width: int = 128\n",
        "    image_height: int = 128\n",
        "    seed: int = 42\n",
        "    # Output\n",
        "    rollout_dir: str = \"./rollouts_mujoco_simple\"\n",
        "\n",
        "def save_rollout_video(rollout_images, idx, success, rollout_dir):\n",
        "    os.makedirs(rollout_dir, exist_ok=True)\n",
        "    mp4_path = os.path.join(rollout_dir, f\"episode_{idx}_success_{success}.mp4\")\n",
        "    video_writer = imageio.get_writer(mp4_path, fps=30)\n",
        "    for img in rollout_images:\n",
        "        video_writer.append_data(img)\n",
        "    video_writer.close()\n",
        "    print(f\"Saved rollout MP4 at path {mp4_path}\")\n",
        "    return mp4_path\n",
        "\n",
        "def visualize_rollout(rollout_images, episode_idx):\n",
        "    n_images = len(rollout_images)\n",
        "    n_cols = min(8, n_images)\n",
        "    n_rows = int(np.ceil(n_images / n_cols))\n",
        "    plt.figure(figsize=(2 * n_cols, 2 * n_rows))\n",
        "    for i, img in enumerate(rollout_images):\n",
        "        plt.subplot(n_rows, n_cols, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(f\"Rollout Visualization - Episode {episode_idx}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set your parameters here\n",
        "cfg = GenerateConfig(\n",
        "    pretrained_checkpoint=\"/user_data/sraychau/Storage/ActualProject/OpenVLA_Model\",  # <-- Set this!\n",
        "    num_episodes=2,\n",
        "    max_steps=50,\n",
        "    image_width=128,\n",
        "    image_height=128,\n",
        "    seed=42,\n",
        "    rollout_dir=\"./rollouts_mujoco_simple\"\n",
        ")\n",
        "set_seed_everywhere(cfg.seed)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = get_model(cfg)\n",
        "processor = get_processor(cfg)\n",
        "cfg.unnorm_key = \"bridge_orig\"  # Use bridge_orig dataset statistics for normalization\n",
        "\n",
        "env = MujocoSimpleEnv(image_width=cfg.image_width, image_height=cfg.image_height)\n",
        "print(\"Environment created successfully\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for ep in range(cfg.num_episodes):\n",
        "    print(f\"Starting episode {ep}\")\n",
        "    obs, _ = env.reset()\n",
        "    print(f\"Episode {ep} reset complete, observation shape: {obs['image'].shape}\")\n",
        "    done = False\n",
        "    t = 0\n",
        "    rollout_images = []\n",
        "    sparse_codes_episode = []\n",
        "    success = False\n",
        "    while not done and t < cfg.max_steps:\n",
        "        # Prepare observation for model\n",
        "        observation = {\n",
        "            \"full_image\": obs[\"image\"],\n",
        "            \"state\": obs[\"proprio\"],\n",
        "        }\n",
        "        # Query model for action\n",
        "        action, sparse_code = get_action(cfg, model, observation, task_label=\"move block\", processor=processor)\n",
        "        if sparse_code is not None:\n",
        "            sparse_codes_episode.append(sparse_code)\n",
        "        # Invert gripper action if needed (OpenVLA convention)\n",
        "        action = invert_gripper_action(action)\n",
        "        # Step environment\n",
        "        obs, reward, done, _, info = env.step(action)\n",
        "        rollout_images.append(observation[\"full_image\"])  # Save image for video\n",
        "        t += 1\n",
        "    print(f\"Episode {ep} finished, saving video and visualizing...\")\n",
        "    save_rollout_video(rollout_images, ep, success=done, rollout_dir=cfg.rollout_dir)\n",
        "    visualize_rollout(rollout_images, ep)\n",
        "    if sparse_codes_episode:\n",
        "        sparse_codes_arr = np.concatenate(sparse_codes_episode, axis=0)\n",
        "        np.save(os.path.join(cfg.rollout_dir, f\"episode_{ep}_sparse_codes.npy\"), sparse_codes_arr)\n",
        "        print(f\"Saved sparse codes for episode {ep}, shape: {sparse_codes_arr.shape}\")\n",
        "print(\"All episodes finished\")\n",
        "env.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
