{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Union, Optional\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Configure paths\n",
    "sys.path.insert(0, \"/user_data/sraychau/Storage/ActualProject/openvla-main/experiments\")\n",
    "sys.path.insert(0, \"/user_data/sraychau/Storage/ActualProject/Lec14a_camera_sensor\")\n",
    "\n",
    "# Project imports\n",
    "from Lec14a_camera_sensor.mujoco_gym_env import MujocoSimpleEnv\n",
    "from robot.robot_utils import (\n",
    "    get_model,\n",
    "    get_action,\n",
    "    get_image_resize_size,\n",
    "    set_seed_everywhere,\n",
    "    invert_gripper_action,\n",
    ")\n",
    "from robot.openvla_utils import get_processor\n",
    "from prismatic.models.vlas.sparse_autoencoder import SparseAutoencoderTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded configuration\n",
    "PRETRAINED_CHECKPOINT = \"OpenVLA_Model/\"\n",
    "NUM_EPISODES = 2\n",
    "MAX_STEPS = 50\n",
    "IMAGE_WIDTH = 128\n",
    "IMAGE_HEIGHT = 128\n",
    "SEED = 42\n",
    "ROLLOUT_DIR = \"./rollouts_mujoco_simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GenerateConfig:\n",
    "    # Model parameters\n",
    "    model_family: str = 'openvla'\n",
    "    pretrained_checkpoint: Union[str, Path] = PRETRAINED_CHECKPOINT\n",
    "    load_in_8bit: bool = False\n",
    "    load_in_4bit: bool = False\n",
    "    center_crop: bool = False\n",
    "    unnorm_key: Optional[str] = None\n",
    "    # Env parameters\n",
    "    num_episodes: int = NUM_EPISODES\n",
    "    max_steps: int = MAX_STEPS\n",
    "    image_width: int = IMAGE_WIDTH\n",
    "    image_height: int = IMAGE_HEIGHT\n",
    "    seed: int = SEED\n",
    "    # Output\n",
    "    rollout_dir: str = ROLLOUT_DIR\n",
    "\n",
    "def save_rollout_video(rollout_images, idx, success, rollout_dir=ROLLOUT_DIR):\n",
    "    os.makedirs(rollout_dir, exist_ok=True)\n",
    "    mp4_path = os.path.join(rollout_dir, f'episode_{idx}_success_{success}.mp4')\n",
    "    video_writer = imageio.get_writer(mp4_path, fps=30)\n",
    "    for img in rollout_images:\n",
    "        video_writer.append_data(img)\n",
    "    video_writer.close()\n",
    "    print(f'Saved rollout MP4 at path {mp4_path}')\n",
    "    return mp4_path\n",
    "\n",
    "def visualize_rollout(rollout_images, episode_idx):\n",
    "    n_images = len(rollout_images)\n",
    "    n_cols = min(8, n_images)\n",
    "    n_rows = int(np.ceil(n_images / n_cols))\n",
    "    plt.figure(figsize=(2 * n_cols, 2 * n_rows))\n",
    "    for i, img in enumerate(rollout_images):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f'Rollout Visualization - Episode {episode_idx}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VLAVenv2",
   "language": "python",
   "name": "VLAVenv2"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
