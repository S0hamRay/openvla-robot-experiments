{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T23:51:50.995587Z",
     "iopub.status.busy": "2025-07-16T23:51:50.995318Z",
     "iopub.status.idle": "2025-07-16T23:52:15.504090Z",
     "shell.execute_reply": "2025-07-16T23:52:15.503334Z"
    },
    "papermill": {
     "duration": 24.512934,
     "end_time": "2025-07-16T23:52:15.505447",
     "exception": false,
     "start_time": "2025-07-16T23:51:50.992513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 19:51:55.065519: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-16 19:51:55.065629: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-16 19:51:55.095069: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-16 19:51:55.161808: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 19:51:56.647944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/sraychau/miniconda3/envs/VLAVenv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 19:52:04.159746: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Union, Optional\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Configure paths\n",
    "sys.path.insert(0, \"/user_data/sraychau/Storage/ActualProject/openvla-main/experiments\")\n",
    "sys.path.insert(0, \"/user_data/sraychau/Storage/ActualProject/Lec14a_camera_sensor\")\n",
    "\n",
    "# Project imports\n",
    "from Lec14a_camera_sensor.mujoco_gym_env import MujocoSimpleEnv\n",
    "from robot.robot_utils import (\n",
    "    get_model,\n",
    "    get_action,\n",
    "    get_image_resize_size,\n",
    "    set_seed_everywhere,\n",
    "    invert_gripper_action,\n",
    ")\n",
    "from robot.openvla_utils import get_processor\n",
    "from prismatic.models.vlas.sparse_autoencoder import SparseAutoencoderTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T23:52:15.510406Z",
     "iopub.status.busy": "2025-07-16T23:52:15.510212Z",
     "iopub.status.idle": "2025-07-16T23:52:15.513927Z",
     "shell.execute_reply": "2025-07-16T23:52:15.513383Z"
    },
    "papermill": {
     "duration": 0.007211,
     "end_time": "2025-07-16T23:52:15.514942",
     "exception": false,
     "start_time": "2025-07-16T23:52:15.507731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hardcoded configuration\n",
    "PRETRAINED_CHECKPOINT = \"OpenVLA_Model/\"\n",
    "NUM_EPISODES = 2\n",
    "MAX_STEPS = 50\n",
    "IMAGE_WIDTH = 128\n",
    "IMAGE_HEIGHT = 128\n",
    "SEED = 42\n",
    "ROLLOUT_DIR = \"./rollouts_mujoco_simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "main",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T23:52:15.519436Z",
     "iopub.status.busy": "2025-07-16T23:52:15.519246Z",
     "iopub.status.idle": "2025-07-16T23:52:15.539836Z",
     "shell.execute_reply": "2025-07-16T23:52:15.539128Z"
    },
    "papermill": {
     "duration": 0.024141,
     "end_time": "2025-07-16T23:52:15.540950",
     "exception": false,
     "start_time": "2025-07-16T23:52:15.516809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GenerateConfig:\n",
    "    # Model parameters\n",
    "    model_family: str = 'openvla'\n",
    "    pretrained_checkpoint: Union[str, Path] = PRETRAINED_CHECKPOINT\n",
    "    load_in_8bit: bool = False\n",
    "    load_in_4bit: bool = False\n",
    "    center_crop: bool = False\n",
    "    unnorm_key: Optional[str] = None\n",
    "    # Env parameters\n",
    "    num_episodes: int = NUM_EPISODES\n",
    "    max_steps: int = MAX_STEPS\n",
    "    image_width: int = IMAGE_WIDTH\n",
    "    image_height: int = IMAGE_HEIGHT\n",
    "    seed: int = SEED\n",
    "    # Output\n",
    "    rollout_dir: str = ROLLOUT_DIR\n",
    "\n",
    "def save_rollout_video(rollout_images, idx, success, rollout_dir=ROLLOUT_DIR):\n",
    "    os.makedirs(rollout_dir, exist_ok=True)\n",
    "    mp4_path = os.path.join(rollout_dir, f'episode_{idx}_success_{success}.mp4')\n",
    "    video_writer = imageio.get_writer(mp4_path, fps=30)\n",
    "    for img in rollout_images:\n",
    "        video_writer.append_data(img)\n",
    "    video_writer.close()\n",
    "    print(f'Saved rollout MP4 at path {mp4_path}')\n",
    "    return mp4_path\n",
    "\n",
    "def visualize_rollout(rollout_images, episode_idx):\n",
    "    n_images = len(rollout_images)\n",
    "    n_cols = min(8, n_images)\n",
    "    n_rows = int(np.ceil(n_images / n_cols))\n",
    "    plt.figure(figsize=(2 * n_cols, 2 * n_rows))\n",
    "    for i, img in enumerate(rollout_images):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f'Rollout Visualization - Episode {episode_idx}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VLAVenv2",
   "language": "python",
   "name": "VLAVenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28.447867,
   "end_time": "2025-07-16T23:52:18.097705",
   "environment_variables": {},
   "exception": null,
   "input_path": "openvla-main/experiments/robot/run_mujoco_simple_eval_with_visualization_sae.ipynb",
   "output_path": "openvla_eval_output.ipynb",
   "parameters": {},
   "start_time": "2025-07-16T23:51:49.649838",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}